This is a statement of the problem, and follow-on info for my McAfee client firewall log parser
---
McAfee firewall logs are difficult to sift.  They are key-value pairs, which are presented in a raw text format, with varying numbers of keys per event, as needed.  Ideally, in order to process this information, it should be in tabular format, which would be more sparse than the raw log text due to rows (individual events) which do not populate a given column (that is, no value is present for a given key).
The input is serialized.  The output should be tabular, with events as rows, keys as columns, and each event/key intersection populated with the value (including null or blank) corresponding to each key.
The advantage of this output format is that it can be analyzed competently by a tool as simple as a spreadsheet with a well-constructed pivot table (in Excel parlance), or any other analytical tool whihc acepts a table as input.
My use case is for McAfee client firewall as adminstered in a corporate, Windows, HBSS / ePolicy environment.  As such, PowerShell is present on every subject machine, and has the chops to reach out and grab a log from any particular machine, given sufficient privileges.  
PowerShell is my chosen tool for this project, but I will stick close to simple methods which can easily be ported to other languages.  I will make use of some .net (Microsoft scripting) methods which make ports to embedded or stand-alone VB or C# scripts or programs simple.
PowerShell can be difficult to harness for arrays, with quirky behavior the native array handling, and more predictable but clunkier .net arrays available just for including a reference.  In my opinion, the clunkier but simpler array handling afforded by the inclusion of .net methods will probably make porting the whole thing simpler, for being less pathologically ^H^H^H idiomatically PowerShell-ish.
The parser will take as input a directory / folder / path *on a single machine*, and parse all logs in that directory into a single output file.  As every log entry (event) is marked with a granular timestamp, integrating events from different logs is straightforward.  Each event in the combined log output will nonetheless be marked with the name of the file it came from, should more detailed reconstruction be necessary by people who know a whole lot more about this stuff than I do.
More to follow.
